{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various models for ML-CUP dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is made up of 11 columns of continuous real numbers. The last two columns represent the targets.<br>\n",
    "So our goal is to develop a multivariate regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ML-CUP22-TR.csv', comment='#', skip_blank_lines=True, index_col=0, header=None)\n",
    "df.index.name = None  #removes index name \n",
    "print(f'Columns number: {df.shape[1]}')\n",
    "print(f'Rows number: {df.shape[0]}')\n",
    "#rename target columns\n",
    "df.rename(columns={10: \"Target_1\", 11: \"Target_2\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Missing values number: {df.isna().sum().sum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the pairplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare linear and rank correlations of the attributes with regard to the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix1 = df.corr(method='pearson').iloc[:-2, -2:]\n",
    "corr_matrix2 = df.corr(method='spearman').iloc[:-2, -2:]\n",
    "\n",
    "# merge the dataframes\n",
    "pd.concat([corr_matrix1, corr_matrix2], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- divide attributes from targets \n",
    "- transform to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split attributes from targets\n",
    "X_df = df.drop(['Target_1', 'Target_2'], axis=1)\n",
    "y_df = df[[\"Target_1\", \"Target_2\"]]\n",
    "\n",
    "# from df to arrays\n",
    "X = X_df.to_numpy()\n",
    "y = y_df.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Validation schema\n",
    "K-Fold CV (K=5) for assessment with internal hold out (25%) for model selection. \n",
    "Final model selection with hold-out (20%) and retrain. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Common framework\n",
    " In order to compare results obtained starting from different hypermodels, we developed a class as a way of sharing methods among them. Thus, each architecture (treated as an instance of the class) follows the same path for model selection and assessment. \n",
    " - `SKLEARN_module.SklNet`: class for Sklearn models  \n",
    " - `KERAS_module.KerasNet`: class for Keras models\n",
    " - separate handling for Pytorch models\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Hyperparameters space searching strategy: **bayesian optimization**. <br>\n",
    "   Because it is a good trade-off between randomness and computational efficiency. Set number of performed trials to 15% of the dimension of the hyperparameters space (computed by the auxiliary function `count_combinations`). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Regularization techniques\n",
    "    Preventing overfitting has been a crucial topic in our analysis. \n",
    "    Namely, we set an artificially high number of epochs (500) for training so that it continues until **early stopping** based on the validation score.\n",
    "    Moreover we decided to **decrease the learning rate** when reaching a plateu on validation loss, so to help approaching a local minimum.\n",
    "    Other regularization techniques relative to each model will be explained in the relative section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Algorithms and hypermodels \n",
    "    In this analysis the following models will be compared using the forementioned procedure:\n",
    "    - ridge regression \n",
    "    - KNN regressor \n",
    "    - SVR \n",
    "    - deep Regression (batch and minibatch)\n",
    "    - RandNN \n",
    "    - CNN\n",
    "    - Cascade Correlation\n",
    "    - linear regression (pytorch)\n",
    "    - shallow regression (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classes and auxiliary functions\n",
    "from SKLEARN_module import SklNet\n",
    "from KERAS_module import KerasNet\n",
    "import tools_for_classes as tools\n",
    "import models_list as models_importer\n",
    "from keras.utils.layer_utils import count_params\n",
    "from sklearn.metrics import  make_scorer\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll intialize two lists containing the MEE score and (an estimation of) the number of effective free parameters for each model.\n",
    "We'll compare the performances of the models with these metrics in the end and decide the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_MEE = []\n",
    "final_dimension = []\n",
    "final_names = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression \n",
    "Construct two linear regressors (one for each target) with penalty term (`alpha`) to bound weights norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                       'estimator__alpha': [0.001, 0.00001, 0.7, 0.9, 1, 2], #penalty term (regularization)\n",
    "                       'estimator__eta0' : [0.01, 0.1, 0.001, 1] #init learning rate\n",
    "                       \n",
    "}\n",
    "\n",
    "# define a custom score for GridSearchCV\n",
    "score = make_scorer(tools.MEE_metric, greater_is_better=False)\n",
    "scoring = score\n",
    "\n",
    "model = models_importer.build_RidgeRegressor(max_iter=500)\n",
    "mode = 'regressione' \n",
    "modelName='ridge'\n",
    "\n",
    "net = SklNet(modelName=modelName, mode=mode, model=model, X=X, y=y, param_grid=hyperParameters_SKLEARN, scoring=scoring)\n",
    "\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(best_params)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(2*X.shape[1])\n",
    "\n",
    "#append results for final plot\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(2*X.shape[1])\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neighbours ranges from 5 to 35 to manage model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                      \"model__estimator__n_neighbors\": np.arange(5, 35, 2),\n",
    "                      \"model__estimator__weights\": [\"uniform\",  \n",
    "                                                 \"distance\"], \n",
    "                      \"model__estimator__metric\": [\"euclidean\", \"cityblock\"], }\n",
    "\n",
    "# define a custom score for GridSearchCV\n",
    "score = make_scorer(tools.MEE_metric, greater_is_better=False)\n",
    "scoring = score\n",
    "\n",
    "model = models_importer.build_KNN_Pipe_Reg()\n",
    "mode = 'reg' \n",
    "modelName = 'knn'\n",
    "\n",
    "net = SklNet(modelName, mode, model, X, y, hyperParameters_SKLEARN, scoring)\n",
    "\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(best_params)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "\n",
    "#vd_dim=number of patterns/k (during training 80% of total data is seen -> 1194)\n",
    "print(1194/best_params['model__estimator__n_neighbors'])\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(1194/best_params['model__estimator__n_neighbors'])\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                         'estimator__C':[0.01, 0.1, 0.3, 0.7, 1.0], # penalty terms (slack variables)\n",
    "                         'estimator__epsilon' : [0.01, 0.1, 0.9, 1.5, 2], #size of the eps-tube\n",
    "                         'estimator__kernel': ['linear','rbf']\n",
    "}\n",
    "\n",
    "# define a custom score for GridSearchCV\n",
    "score = make_scorer(tools.MEE_metric, greater_is_better=False)\n",
    "scoring = score\n",
    "\n",
    "model = models_importer.build_SVR(500)\n",
    "mode = 'reg' \n",
    "modelName = 'svr'\n",
    "\n",
    "net = SklNet(modelName, mode, model, X, y, hyperParameters_SKLEARN, scoring)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category=ConvergenceWarning)\n",
    "    best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(best_params)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "\n",
    "if best_params['estimator__kernel']=='rbf':\n",
    "    #complexity expected to be infinite so we'll assign at the end the maximum complexity found\n",
    "    complexity= -1\n",
    "if best_params['estimator__kernel']=='linear':\n",
    "    complexity = 2*X.shape[1]\n",
    "print(\"Effective free parameters\")\n",
    "print(complexity)\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(complexity)\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep Regression (keras)\n",
    " We selected 5 hyperparameters: `units` and `depth` to decide the net's structure,`learning_rate` and `decay` to tweak the optimizer's parameters and `dropout` for regularization purposes.\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use different batch sizes to compare our model's performance varying this hyperparameter. We will try  mini batch with size 64 and batch (batch_size=len(X)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini batch size 64\n",
    "mode='regression'\n",
    "hyperp = {\n",
    "                'output_units' : 2,\n",
    "                'units' : [4,5,6,7], #number of units in each hidden layer\n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-3],\n",
    "                'depth':[2,4,1], #number of hidden layers\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'linear',\n",
    "                'metric': 'MSE'\n",
    "            }\n",
    "\n",
    "models_importer.set_input_size(len(X[0])) #set input units\n",
    "models_importer.set_hyperp(hyperp) #pass user defined hps to the model    \n",
    "modelBuilder = models_importer.get_deepNN    #hypermodel function definition\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)    #total combinations of hps\n",
    "modelName='deep_mb'\n",
    "\n",
    "#auxiliary parameters for hps search\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'deep_mb',\n",
    "            'batch_size': 64,\n",
    "            'max_trials' : 0.15*tot_trials,\n",
    "        }\n",
    "\n",
    "# hps search, train and test \n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X, y=y, tunerParameters=tunerParameters, modelBuilder=modelBuilder )\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "    \n",
    "print(\"Best params\")\n",
    "print(best_params.values)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "mode='regression'\n",
    "hyperp = {\n",
    "                'output_units' : 2,\n",
    "                'units' : [4,5,6,7],\n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-3],\n",
    "                'depth':[2,4,1],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'linear',\n",
    "                'metric': 'MSE'\n",
    "            }\n",
    "\n",
    "\n",
    "models_importer.set_input_size(len(X[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_deepNN\n",
    "\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)\n",
    "modelName='deep_b'\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'deep_b',\n",
    "            'batch_size': 1492,\n",
    "            'max_trials' : 0.15*tot_trials\n",
    "}\n",
    "\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X, y=y, tunerParameters=tunerParameters, modelBuilder=modelBuilder )\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best params\")\n",
    "print(best_params.values)   \n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingParameters_KERAS = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'regr_adam_kfold',\n",
    "            'batch_size': 64,\n",
    "            'max_trials' : 0.15*tot_trials,\n",
    "        }\n",
    "\n",
    "hyperp = {\n",
    "                'units' : [5,7,10],\n",
    "                'output_units' : 2, \n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-3],\n",
    "                'depth':[2,6 ,1],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'linear',\n",
    "                'metric': 'MSE'\n",
    "            }\n",
    "models_importer.set_input_size(len(X[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_RandNN\n",
    "mode = 'reg'\n",
    "modelName='RandNN'\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X, y=y, tunerParameters=trainingParameters_KERAS,\n",
    "                        modelBuilder=modelBuilder)\n",
    "\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best params\")\n",
    "print(best_params.values)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing a CNN architecture, we implicitly assume that the attributes' position has some kind of significance \n",
    "(eg. column lying next to each other are somehow more related than further apart ones). \n",
    "Note that this is not directly implied by the data. However, the net could pick up on non-linear correlations between \n",
    "\"close\" attributes.\n",
    "Although this model is mostly used for datasets which underly a pattern-like structure (eg. images), we tried it\n",
    "anyway for experimentation's sake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingParameters_KERAS = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'regr_adam_kfold',\n",
    "            'batch_size': 64,\n",
    "            'max_trials' : 18,  #all of the possibilities\n",
    "        }\n",
    "\n",
    "hyperp = {\n",
    "                'units' : [10,20,30],\n",
    "                'output_units' : 2, \n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-4, 1e-3],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'linear',\n",
    "                'metric': 'MSE'\n",
    "            }\n",
    "models_importer.set_input_size(len(X[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_CNN\n",
    "mode = 'reg'\n",
    "modelName='cnn'\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X, y=y, tunerParameters=trainingParameters_KERAS,\n",
    "                        modelBuilder=modelBuilder)\n",
    "\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_err = net.train()\n",
    "\n",
    "print(\"Best params\")\n",
    "print(best_params.values)\n",
    "print(\"Training Error\")\n",
    "print(best_training_err)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test_MEE \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library source code at https://github.com/mike-gimelfarb/cascade-correlation-neural-networks .  \n",
    "Follows canonical cascade correlation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingParameters_KERAS = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'regr_adam_kfold',\n",
    "            'batch_size': 64,\n",
    "            'max_trials' : 1,    #no hyperparameters\n",
    "        }\n",
    "\n",
    "hyperp = {}\n",
    "\n",
    "\n",
    "models_importer.set_input_size(len(X[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_CC_units\n",
    "mode = 'reg'\n",
    "modelName='cc'\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X, y=y, tunerParameters=trainingParameters_KERAS,\n",
    "                        modelBuilder=modelBuilder)\n",
    "\n",
    "best_model, best_model_MEE_val, best_params, mean_test_error, stdev_test_error, best_training_error = net.train()\n",
    "print(best_params)\n",
    "\n",
    "print(\"Training error\")\n",
    "print(best_training_error)\n",
    "print(\"Validation Error\")\n",
    "print(best_model_MEE_val)\n",
    "print(\"Test error \")\n",
    "print(f'{mean_test_error} +/- {stdev_test_error}')\n",
    "print(\"Effective free parameters\")\n",
    "print(tools.get_param_cc(n_in=9, n_out=2, n_hid=sum(best_params)))\n",
    "\n",
    "final_MEE.append([mean_test_error, stdev_test_error])\n",
    "final_dimension.append(tools.get_param_cc(n_in=9, n_out=2, n_hid=sum(best_params)))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we used Pytorch on two simple architectures:\n",
    "- a one layer linear regressor \n",
    "- a shallow net with 4 hidden units and a linear activation function \n",
    "\n",
    "The validation strategy is the same as forementioned; however, for the final retraining, we chose to train over the whole dataset and pick the mean number of epochs, obtained from the cross validation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, train_test_split\n",
    "from tools_for_Pytorch import EarlyStopping, weights_init_uniform_fan_in, count_parameters\n",
    "from tools_for_classes import MEE_metric, save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform attributes and targets to tensors\n",
    "X = torch.from_numpy(X_df.to_numpy(dtype=np.float32))\n",
    "y = torch.from_numpy(y_df.to_numpy(dtype=np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global test_mse_list, test_mee_list, epochs_list\n",
    "\n",
    "test_mse_list = []\n",
    "test_mee_list = []\n",
    "epochs_list = []\n",
    "\n",
    "\n",
    "def train(model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test, name=None):\n",
    "\n",
    "    '''Performs the forward and backwards training loop until early stopping, then computes the metric(s)'''\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    epochs = 500\n",
    "    epoch_count = []\n",
    "\n",
    "    train_mse_values = []\n",
    "    val_mse_values = []\n",
    "    test_mse_values = []\n",
    "\n",
    "    train_mee_values = []\n",
    "    val_mee_values = []\n",
    "    test_mee_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train mode\n",
    "        model.train()\n",
    "\n",
    "        # 1. Forward pass on train data\n",
    "        train_pred = model(X_train)\n",
    "        \n",
    "        # 2. Calculate the loss\n",
    "        train_mse = loss_fn(train_pred, y_train)\n",
    "        train_mee = MEE_metric(y_train.numpy(), train_pred.detach().numpy())\n",
    "\n",
    "        # 3. Zero grad of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Backpropagation\n",
    "        train_mse.backward()\n",
    "        \n",
    "        # 5. Progress the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # make predictions with model without gradient tracking \n",
    "        with torch.inference_mode():\n",
    "\n",
    "            # 1. Forward pass on validation and test data\n",
    "            val_pred = model(X_val)\n",
    "            test_pred = model(X_test)\n",
    "\n",
    "            # 2. Caculate mse and mee on validation and test data        \n",
    "            val_mse = loss_fn(val_pred, y_val)                    \n",
    "            test_mse = loss_fn(test_pred, y_test)\n",
    "            val_mee = MEE_metric(y_val.numpy(), val_pred.numpy())                    \n",
    "            test_mee = MEE_metric(y_test.numpy(), test_pred.numpy())        \n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_mse_values.append(train_mse)\n",
    "        val_mse_values.append(val_mse)\n",
    "        test_mse_values.append(test_mse)\n",
    "\n",
    "        train_mee_values.append(train_mee)\n",
    "        val_mee_values.append(val_mee)\n",
    "        test_mee_values.append(test_mee)\n",
    "    \n",
    "        # early_stopping needs the validation loss to check if it has decreased\n",
    "        early_stopping(val_mse, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch is {epoch:<3} | Training MSE: {train_mse:.3f} | Validation MSE: {val_mse:.3f} | Trainining MEE: {train_mee:.3f} | Val MEE: {val_mee:.3f}\")\n",
    "\n",
    "    print(f\"Epoch is {epoch:<3} \\nTraining MSE: {train_mse:.3f} | Validation MSE: {val_mse:.3f} | Test MSE: {test_mse:.3f}\")\n",
    "    print(f\"Training MEE: {train_mee:.3f} | Validation MEE: {val_mee:.3f} | Test MEE: {test_mee:.3f}\")\n",
    "\n",
    "    test_mse_list.append(test_mse_values[-1])\n",
    "    test_mee_list.append(test_mee_values[-1])\n",
    "    epochs_list.append(epoch_count[-1])\n",
    "\n",
    "    if name: \n",
    "        fig,ax = plt.subplots()\n",
    "        plt.plot(epoch_count, np.array(torch.tensor(train_mse_values).numpy()), label=\"Training MSE\")\n",
    "        plt.plot(epoch_count, val_mse_values, label=\"Validation MSE\", linestyle='dashed')\n",
    "        plt.title(name  + \" TR and VL MSE\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        folder = 'Pytorch-plots'\n",
    "        save_plot(folder, name)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_retraining(model, optimizer, X, y, epochs, name=None):\n",
    "    \n",
    "    '''Performs a final retraining over the whole dataset'''\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    epoch_count = []\n",
    "    train_mse_values = []\n",
    "    train_mee_values = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train mode\n",
    "        model.train()\n",
    "\n",
    "        # 1. Forward pass on train data\n",
    "        train_pred = model(X)\n",
    "        \n",
    "        # 2. Calculate the loss\n",
    "        train_mse = loss_fn(train_pred, y)\n",
    "        train_mee = MEE_metric(y.numpy(), train_pred.detach().numpy())\n",
    "\n",
    "        # 3. Zero grad of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Backpropagation\n",
    "        train_mse.backward()\n",
    "        \n",
    "        # 5. Progress the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_count.append(epoch)\n",
    "        train_mse_values.append(train_mse)\n",
    "        train_mee_values.append(train_mee)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch is {epoch:<3} | Training MSE: {train_mse:.3f} | Trainining MEE: {train_mee:.3f}\")\n",
    "\n",
    "    print(f\"Epoch is {epoch:<3} | Training MSE: {train_mse:.3f} | Training MEE: {train_mee:.3f}\")\n",
    "\n",
    "    if name: \n",
    "        fig,ax = plt.subplots()\n",
    "        plt.plot(epoch_count, np.array(torch.tensor(train_mse_values).numpy()), label=\"Training MSE\")\n",
    "        plt.title(name  + \" TR MSE\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        folder = 'Pytorch-plots'\n",
    "        save_plot(folder, name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5   # number of folds used in k-fold\n",
    "VAL_SPLIT = 1/(K-1) # validation split in k-fold\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "outer_kfold = KFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\n",
    "inner_holdout = ShuffleSplit(n_splits=1, test_size=VAL_SPLIT, random_state=RANDOM_STATE)\n",
    "w_init = weights_init_uniform_fan_in\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mee_list = []\n",
    "epochs_list = []\n",
    "\n",
    "name = 'pt_LR'\n",
    "\n",
    "# outer loop for k times\n",
    "for i, (dev_idx, test_idx) in enumerate(outer_kfold.split(X)):        \n",
    "        X_dev, X_test = X[dev_idx], X[test_idx]\n",
    "        y_dev, y_test = y[dev_idx], y[test_idx]\n",
    "\n",
    "        print(f'\\nFOLD N. {i+1}')\n",
    "\n",
    "        # inner hold-out\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=VAL_SPLIT, shuffle=False)\n",
    "        \n",
    "        model = nn.Sequential(nn.Linear(in_features=9, out_features=2))\n",
    "\n",
    "        # weights initialization \n",
    "        model.apply(w_init)\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "        train(model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test, name=name)\n",
    "\n",
    "# computes the mean over the folds\n",
    "mean_test_mee_error = np.mean(test_mee_list)\n",
    "stdev_test_mee_error = np.std(test_mee_list)\n",
    "mean_epochs = int(np.ceil(np.mean(epochs_list)))\n",
    "\n",
    "print(f'\\nMean epoch count: {mean_epochs} +/- {np.std(epochs_list):.0f}')\n",
    "print(f'Test MEE: {mean_test_mee_error:.3f} +/- {stdev_test_mee_error:.3f}')\n",
    "\n",
    "parameters_count = count_parameters(model)\n",
    "print(f'Effective free paramters: {parameters_count}')\n",
    "\n",
    "final_MEE.append([mean_test_mee_error, stdev_test_mee_error])\n",
    "final_dimension.append(parameters_count)\n",
    "final_names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(in_features=9, out_features=2))\n",
    "\n",
    "# weights initialization\n",
    "model.apply(w_init)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "final_retraining(model, optimizer, X=X, y=y, epochs=mean_epochs, name=name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mee_list = []\n",
    "epochs_list = []\n",
    "\n",
    "name = 'pt_4hid'\n",
    "\n",
    "# outer loop for k times\n",
    "for i, (dev_idx, test_idx) in enumerate(outer_kfold.split(X)):        \n",
    "        X_dev, X_test = X[dev_idx], X[test_idx]\n",
    "        y_dev, y_test = y[dev_idx], y[test_idx]\n",
    "\n",
    "        print(f'\\nFOLD N. {i+1}')\n",
    "\n",
    "        # inner hold-out\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=VAL_SPLIT, shuffle=False)\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "                nn.Linear(in_features=9, out_features=4),\n",
    "                nn.Linear(in_features=4, out_features=2),\n",
    "                )\n",
    "        \n",
    "        # weights initialization\n",
    "        model.apply(w_init)\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "        train(model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test, name=name)\n",
    "\n",
    "# computes the mean over the folds\n",
    "mean_test_mee_error = np.mean(test_mee_list)\n",
    "stdev_test_mee_error = np.std(test_mee_list)\n",
    "mean_epochs = int(np.ceil(np.mean(epochs_list)))\n",
    "\n",
    "print(f'\\nMean epoch count: {mean_epochs} +/- {np.std(epochs_list):.0f}')\n",
    "print(f'Test MEE: {mean_test_mee_error:.3f} +/- {stdev_test_mee_error:.3f}')\n",
    "\n",
    "parameters_count = count_parameters(model)\n",
    "print(f'Effective free parameters: {parameters_count}')\n",
    "\n",
    "final_MEE.append([mean_test_mee_error, stdev_test_mee_error])\n",
    "final_dimension.append(parameters_count)\n",
    "final_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(in_features=9, out_features=4),\n",
    "        nn.Linear(in_features=4, out_features=2),\n",
    "        )\n",
    "\n",
    "model.apply(w_init)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "final_retraining(model, optimizer, X=X, y=y, epochs=mean_epochs, name=name)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparison "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the model we have just built in relationship with their complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substitute rbf value with maximum of the list\n",
    "final_dimension[final_dimension.index(-1)] = max(final_dimension)\n",
    "\n",
    "#unpack mean and std\n",
    "final_mean, final_std = zip(*final_MEE)\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.xlabel('Effective free parameters')\n",
    "plt.ylabel('MEE')\n",
    "\n",
    "#scatter plot\n",
    "for i, txt in enumerate(final_names):\n",
    "    ax.errorbar(final_dimension[i], final_mean[i], yerr=final_std[i], label=final_names[i],fmt='.')\n",
    "    ax.annotate(txt, (final_dimension[i], final_mean[i]))\n",
    "folder = 'ML-CUP-plots'\n",
    "tools.save_plot(folder, 'final')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "print(f'Elapsed time: {time.time()-start}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
