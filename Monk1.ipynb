{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "Monk datasets are made up of 6 descrete attributes with binary targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import models_list as models_importer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "start=time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing consists simply in getting the one-hot encoded version of the inputs and the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path, tensor=False):\n",
    "    # read csv\n",
    "    df = pd.read_csv(path, sep='\\s+', skip_blank_lines=False, skipinitialspace=False, names=[\"class\", 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID'])\n",
    "\n",
    "    X_df = df.drop(['class', 'ID'], axis=1)\n",
    "    y_df = df[['class']]\n",
    "\n",
    "    # one-hot encoding\n",
    "    X_df = pd.get_dummies(X_df, columns=X_df.columns)\n",
    "\n",
    "    if tensor:\n",
    "        X = torch.from_numpy(X_df.to_numpy(dtype=np.float32))\n",
    "        y = torch.from_numpy(y_df.to_numpy(dtype=np.float32))\n",
    "    else:\n",
    "        X = X_df.to_numpy()\n",
    "        y = y_df.to_numpy()\n",
    "    \n",
    "    X, y = unison_shuffled_copies(X, y)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'monk/monks-1.train'\n",
    "X_train, y_train = preprocessing(path)\n",
    "\n",
    "path = 'monk/monks-1.test'\n",
    "X_test, y_test = preprocessing(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "The process is alalogous to the one used for regression. The main difference here is the model selection and model assessment approach.   \n",
    "Now we select the best model with an hold-out in the train set (75% of data used for train and 25% used for validation).   \n",
    "Since in this case we are given train and test sets separately, we perform model assessment with the pre-made hold-out.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis the following models will be compared using the forementioned procedure: \n",
    "- ridge classification (sklearn)\n",
    "- KNN classification\n",
    "- SVM \n",
    "- deep model for classification (keras)\n",
    "- RandNN for classification\n",
    "- CNN for classification\n",
    "- Cascade Correlation\n",
    "- linear classification (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classes and auxiliary functions\n",
    "from SKLEARN_module import SklNet\n",
    "from KERAS_module import KerasNet\n",
    "import tools_for_classes as tools\n",
    "import models_list as models_importer\n",
    "from keras.utils.layer_utils import count_params\n",
    "from sklearn.metrics import  make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lists for final comparison\n",
    "final_acc = []\n",
    "final_dimension = []\n",
    "final_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                      \"model__n_neighbors\": np.arange(5, 35, 2),\n",
    "                      \"model__weights\": [\"uniform\",  \n",
    "                                                 \"distance\"], \n",
    "                      \"model__metric\": [\"euclidean\", \"cityblock\"], }\n",
    "\n",
    "\n",
    "model = models_importer.build_KNN_Pipe_Clf()\n",
    "mode = 'classification' \n",
    "modelName = 'knn'\n",
    "net = SklNet(modelName, mode, model, X_train, np.ravel(y_train), hyperParameters_SKLEARN, X_test=X_test, y_test=y_test)\n",
    "best_model, best_params_val, MSE_test, MSE_training, accuracy_training, accuracy_test  = net.train()\n",
    "\n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(MSE_test)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"best params\")\n",
    "print(best_params_val)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "#vd_dim=number of patterns/k (during training 75% of total data is seen -> 93)\n",
    "print(93/best_params_val['model__n_neighbors'])\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(93/best_params_val['model__n_neighbors'])\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                         'C':[0.01,0.1, 0.2, 0.3, 0.7, 1.0, 2.0], #small C => high value of slack => underfit\n",
    "                                                   #high C  => small value of slack => overfit\n",
    "                         #'degree' : [1,2,3,4] not used if kernel is linear\n",
    "}\n",
    "\n",
    "model = models_importer.build_SVM(500)\n",
    "mode = 'clf' \n",
    "modelName='svm'\n",
    "net = SklNet(modelName, mode, model, X_train, np.ravel(y_train), hyperParameters_SKLEARN, X_test = X_test, y_test = y_test)\n",
    "best_model, best_params_val, MSE_test, MSE_training, accuracy_training, accuracy_test  = net.train()\n",
    "\n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(MSE_test)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"best params\")\n",
    "print(best_params_val)\n",
    "\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "#n+1 where n is the dimension of the pattern\n",
    "print(18)\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(18)\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameters_SKLEARN = {\n",
    "                       'alpha': [0.001, 0.00001, 0.7, 0.9, 1, 2],\n",
    "                       'eta0' : [0.01, 0.1, 0.001, 1], #init learning rate\n",
    "                       \n",
    "}\n",
    "\n",
    "model = models_importer.build_RidgeClassifier(max_iter=50)\n",
    "mode = 'classification' \n",
    "modelName='ridge'\n",
    "net = SklNet(modelName, mode, model, X_train, np.ravel(y_train), hyperParameters_SKLEARN, X_test=X_test, y_test=y_test)\n",
    "best_model, best_params_val, MSE_test, MSE_training, accuracy_training, accuracy_test = net.train()\n",
    "\n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(MSE_test)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"best params\")\n",
    "print(best_params_val)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(17*2)\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(17*2)\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini batch size 32\n",
    "mode='classification'\n",
    "hyperp = {\n",
    "               'output_units' : 1,\n",
    "                'units' : [2,3,4,5,6],\n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-4, 1e-3],\n",
    "                'depth':[1,3,1],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'sigmoid',\n",
    "                'metric': 'accuracy'\n",
    "            }\n",
    "models_importer.set_input_size(len(X_train[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_deepNN\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)\n",
    "print(tot_trials)\n",
    "modelName='deep_mb'\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'deep_mb',\n",
    "            'batch_size': 32,\n",
    "            'max_trials' : 0.2*tot_trials\n",
    "            #'max_trials' : 0.002*tot_trials,\n",
    "        }\n",
    "\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X_train, y=y_train, tunerParameters=tunerParameters, modelBuilder=modelBuilder, X_test=X_test, y_test=y_test )\n",
    "best_model, best_hps, MSE_training, accuracy_training, best_model_MSE_TEST, accuracy_test = net.train()\n",
    "\n",
    "    \n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(best_model_MSE_TEST)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"Best params\")\n",
    "print(best_hps.values)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "mode='classification'\n",
    "hyperp = {\n",
    "               'output_units' : 1,\n",
    "                'units' : [2,3,4,5,6],\n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-4, 1e-3],\n",
    "                'depth':[1,3,1],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'sigmoid',\n",
    "                'metric': 'accuracy'\n",
    "            }\n",
    "models_importer.set_input_size(len(X_train[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_deepNN\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)\n",
    "print(tot_trials)\n",
    "modelName='deep_b'\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'deep_b',\n",
    "            'batch_size': 124,\n",
    "            'max_trials' : 0.2*tot_trials\n",
    "            #'max_trials' : 0.002*tot_trials,\n",
    "        }\n",
    "\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X_train, y=y_train, tunerParameters=tunerParameters, modelBuilder=modelBuilder, X_test=X_test, y_test=y_test )\n",
    "best_model, best_hps, MSE_training, accuracy_training, best_model_MSE_TEST, accuracy_test = net.train()\n",
    "\n",
    "    \n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(best_model_MSE_TEST)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"Best params\")\n",
    "print(best_hps.values)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='classification'\n",
    "hyperp = {\n",
    "                'output_units' : 1,\n",
    "                'units' : [3,4,5,6],\n",
    "                'dropout' : [1e-3, 0.0],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-4, 1e-3],\n",
    "                'depth':[1,4,1],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'sigmoid',\n",
    "                'metric': 'accuracy'\n",
    "            }\n",
    "models_importer.set_input_size(len(X_train[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_RandNN\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)\n",
    "print(tot_trials)\n",
    "modelName='randNN'\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'deep_b',\n",
    "            'batch_size': 124,\n",
    "            'max_trials' : 0.2*tot_trials\n",
    "            #'max_trials' : 0.002*tot_trials,\n",
    "        }\n",
    "\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X_train, y=y_train, tunerParameters=tunerParameters, modelBuilder=modelBuilder, X_test=X_test, y_test=y_test )\n",
    "best_model, best_hps, MSE_training, accuracy_training, best_model_MSE_TEST, accuracy_test = net.train()\n",
    "\n",
    "    \n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(best_model_MSE_TEST)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"Best params\")\n",
    "print(best_hps.values)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='classification'\n",
    "hyperp = {\n",
    "               'output_units' : 1,\n",
    "                'units' : [4,6,8],\n",
    "                'learning_rate': [1e-2, 1e-3],\n",
    "                'decay': [0.0, 1e-4, 1e-3],\n",
    "                'activation_hidden': 'relu',\n",
    "                'activation_output':'sigmoid',\n",
    "                'metric': 'accuracy'\n",
    "            }\n",
    "\n",
    "models_importer.set_input_size(len(X_train[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelBuilder = models_importer.get_CNN\n",
    "tot_trials = tools.get_search_spaze_size(hyperp)\n",
    "print(tot_trials)\n",
    "modelName='cnn'\n",
    "tunerParameters = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'cnn',\n",
    "            'batch_size': 124,\n",
    "            'max_trials' : 0.2*tot_trials\n",
    "            #'max_trials' : 0.002*tot_trials,\n",
    "        }\n",
    "\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X_train, y=y_train, tunerParameters=tunerParameters, modelBuilder=modelBuilder, X_test=X_test, y_test=y_test )\n",
    "best_model, best_hps, MSE_training, accuracy_training, best_model_MSE_TEST, accuracy_test = net.train()\n",
    "\n",
    "    \n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(best_model_MSE_TEST)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"Best params\")\n",
    "print(best_hps.values)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(count_params(best_model.trainable_weights))\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(count_params(best_model.trainable_weights))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingParameters_KERAS = {\n",
    "            'directory' : 'tuner',\n",
    "            'project_name':'classification_monk',\n",
    "            'batch_size': 1,\n",
    "            'max_trials' : 10,\n",
    "        }\n",
    "\n",
    "hyperp = {}\n",
    "\n",
    "mode = 'classification'\n",
    "models_importer.set_input_size(len(X_train[0]))\n",
    "models_importer.set_hyperp(hyperp)\n",
    "modelName='cc'\n",
    "\n",
    "modelBuilder = models_importer.get_CC_units\n",
    "net = KerasNet(modelName=modelName, mode=mode, X=X_train, y=y_train, tunerParameters=trainingParameters_KERAS,\n",
    "                        modelBuilder=modelBuilder, X_test=X_test, y_test=y_test)\n",
    "\n",
    "#best_hps = num.hidden\n",
    "model, MSE_training, accuracy_training, best_model_MSE_TEST, accuracy_test, num_hidden = net.train()\n",
    "print(\"MSE train\")\n",
    "print(MSE_training)\n",
    "print(\"accuracy train\")\n",
    "print(accuracy_training)\n",
    "print(\"MSE test\")\n",
    "print(best_model_MSE_TEST)\n",
    "print(\"accuracy test\")\n",
    "print(accuracy_test)\n",
    "print(\"Best params\")\n",
    "print(num_hidden)\n",
    "\n",
    "print(\"Effective free parameters\")\n",
    "print(tools.get_param_cc(n_in=17, n_out=1, n_hid=sum(num_hidden)))\n",
    "\n",
    "final_acc.append(accuracy_test)\n",
    "final_dimension.append(tools.get_param_cc(n_in=17, n_out=1, n_hid=sum(num_hidden)))\n",
    "final_names.append(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools_for_Pytorch import EarlyStopping, weights_init_uniform_fan_in, count_parameters\n",
    "from tools_for_classes import save_plot\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'monk/monks-1.train'\n",
    "X_dev, y_dev = preprocessing(path, tensor=True)\n",
    "\n",
    "path = 'monk/monks-1.test'\n",
    "X_test, y_test = preprocessing(path, tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SPLIT = 0.25\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=VAL_SPLIT, shuffle = True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global test_acc_list\n",
    "\n",
    "test_acc_list = []\n",
    "\n",
    "def train(name, model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    early_stopping = EarlyStopping(delta=0.01)\n",
    "    train_accuracy = torchmetrics.Accuracy(task='binary')\n",
    "    val_accuracy = torchmetrics.Accuracy(task='binary')\n",
    "    test_accuracy = torchmetrics.Accuracy(task='binary')\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    epochs = 500\n",
    "\n",
    "    epoch_count = []\n",
    "\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "    test_loss_values = []\n",
    "\n",
    "    train_acc_values = []\n",
    "    val_acc_values = []\n",
    "    test_acc_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train mode\n",
    "        model.train()\n",
    "\n",
    "        # 1. Forward pass on train data\n",
    "        train_pred = model(X_train)\n",
    "        \n",
    "        # 2. Calculate the loss and the accuracy\n",
    "        train_loss = loss_fn(train_pred, y_train)\n",
    "        train_acc = train_accuracy(train_pred, y_train)\n",
    "\n",
    "        # 3. Zero grad of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Backpropagation\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # 5. Progress the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # make predictions with model without gradient tracking \n",
    "        with torch.inference_mode():\n",
    "\n",
    "            # 1. Forward pass on validation and test data\n",
    "            val_pred = model(X_val)\n",
    "            test_pred = model(X_test)\n",
    "\n",
    "            # 2. Calculate loss and accuracy on validation and test data        \n",
    "            val_loss = loss_fn(val_pred, y_val)                    \n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "            val_acc = val_accuracy(val_pred, y_val)\n",
    "            test_acc = test_accuracy(test_pred, y_test)        \n",
    "        \n",
    "        train_accuracy.reset()\n",
    "        val_accuracy.reset()\n",
    "        test_accuracy.reset()\n",
    "\n",
    "        epoch_count.append(epoch)\n",
    "\n",
    "        train_loss_values.append(train_loss)\n",
    "        val_loss_values.append(val_loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "\n",
    "        train_acc_values.append(train_acc)\n",
    "        val_acc_values.append(val_acc)\n",
    "        test_acc_values.append(test_acc)\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decreased, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch is {epoch:<3} | Training loss: {train_loss:.3f} | Validation loss: {val_loss:.3f} | Training accuracy: {train_acc:.3f} | Validation accuracy: {val_acc:.3f}\")\n",
    "\n",
    "    print(f\"Epoch is {epoch:<3} \\nTraining loss: {train_loss:.3f} | Validation loss: {val_loss:.3f}| Test loss: {test_loss:.3f} \\nTraining accuracy: {train_acc:.3f} | Validation accuracy: {val_acc:.3f}| Test accuracy: {test_acc:.3f}\")\n",
    "    \n",
    "    test_acc_list.append(test_acc_values[-1])\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epoch_count, np.array(torch.tensor(train_loss_values).numpy()), label=\"Training Loss\")\n",
    "    plt.plot(epoch_count, val_loss_values, label=\"Validation Loss\", linestyle='dashed')\n",
    "    plt.title(\"TR and VS Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epoch_count, np.array(torch.tensor(train_acc_values).numpy()), label=\"Training Accuracy\")\n",
    "    plt.plot(epoch_count, val_acc_values, label=\"Validation Accuracy\", linestyle='dashed')\n",
    "    plt.title(\"TR and VS Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.suptitle(name)\n",
    "    plt.tight_layout()\n",
    "    folder = 'Pytorch_Monk1-plots'\n",
    "    save_plot(folder, name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_list = []\n",
    "\n",
    "name = 'pt_LC'\n",
    "\n",
    "w_init=weights_init_uniform_fan_in\n",
    "lr=1\n",
    "\n",
    "model = nn.Sequential(\n",
    "     nn.Linear(in_features=17, out_features=1),\n",
    "     nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.apply(w_init)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train(name, model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "parameters_count = count_parameters(model)\n",
    "print(f'Effective free parameters: {parameters_count}')\n",
    "\n",
    "test_acc = test_acc_list[-1]\n",
    "\n",
    "final_acc.append(test_acc)\n",
    "final_dimension.append(parameters_count)\n",
    "final_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_list = []\n",
    "\n",
    "name = 'pt_2hid'\n",
    "\n",
    "w_init=weights_init_uniform_fan_in\n",
    "hid = 2\n",
    "lr=0.3\n",
    "\n",
    "model = nn.Sequential(\n",
    "     nn.Linear(in_features=17, out_features=hid),\n",
    "     nn.Linear(in_features=hid, out_features=1),\n",
    "     nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.apply(w_init)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train(name, model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "parameters_count = count_parameters(model)\n",
    "print(f'Effective free parameters: {parameters_count}')\n",
    "\n",
    "test_acc = test_acc_list[-1]\n",
    "\n",
    "final_acc.append(test_acc)\n",
    "final_dimension.append(parameters_count)\n",
    "final_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_list = []\n",
    "\n",
    "name = 'pt_4hid'\n",
    "\n",
    "w_init=weights_init_uniform_fan_in\n",
    "hid = 4\n",
    "lr=0.4\n",
    "\n",
    "model = nn.Sequential(\n",
    "     nn.Linear(in_features=17, out_features=hid),\n",
    "     nn.Linear(in_features=hid, out_features=1),\n",
    "     nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.apply(w_init)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train(name, model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "parameters_count = count_parameters(model)\n",
    "print(f'Effective free parameters: {parameters_count}')\n",
    "\n",
    "test_acc = test_acc_list[-1]\n",
    "\n",
    "final_acc.append(test_acc)\n",
    "final_dimension.append(parameters_count)\n",
    "final_names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dim = final_dimension\n",
    "print(final_dim)\n",
    "#final_dim = np.array(final_dim)/124\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(x=final_dim, y= final_acc, fmt='.')\n",
    "plt.xlabel('effective_free_params')\n",
    "plt.ylabel('Accuracy')\n",
    "for i, txt in enumerate(final_names):\n",
    "    ax.annotate(txt, (final_dim[i], final_acc[i]))\n",
    "folder = 'Monk-plots'\n",
    "tools.save_plot(folder, 'final_plot')\n",
    "plt.show()\n",
    "\n",
    "print(f'Elapsed time {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
